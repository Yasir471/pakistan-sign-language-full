#!/usr/bin/env python3
"""
Pakistani Sign Language Translation App with 3D Character
Complete application with Speech-to-Sign, Text-to-Sign, and 3D animated character
"""

import argparse
import json
import time
import threading
import os
from pathlib import Path
import speech_recognition as sr
import pyttsx3
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class PakistaniSignLanguageApp:
    def __init__(self, labels_path="labels.json", images_path="gesture_images/"):
        """Initialize the complete sign language application"""
        print("ğŸš€ Initializing Pakistani Sign Language Translation App...")
        
        # Load gesture labels and mappings
        try:
            with open(labels_path, 'r', encoding='utf-8') as f:
                self.labels = json.load(f)
            print(f"âœ… Loaded {len(self.labels)} gesture labels")
        except Exception as e:
            print(f"âŒ Error loading labels: {e}")
            return
        
        # Create reverse mapping for text to gesture lookup
        self.create_text_mappings()
        
        # Initialize speech recognizer
        self.recognizer = sr.Recognizer()
        try:
            self.microphone = sr.Microphone()
            
            # Adjust for ambient noise
            print("ğŸ”§ Calibrating microphone for ambient noise...")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=2)
            print("âœ… Microphone calibrated")
        except Exception as e:
            print(f"âš ï¸ Microphone not available: {e}")
            self.microphone = None
        
        # Initialize TTS for feedback
        try:
            self.tts = pyttsx3.init()
            self.tts.setProperty('rate', 150)
            self.tts.setProperty('volume', 0.8)
            print("âœ… Text-to-speech initialized")
        except:
            self.tts = None
            print("âš ï¸ TTS not available")
        
        # Gesture images path
        self.images_path = Path(images_path)
        self.images_path.mkdir(exist_ok=True)
        
        # Create sample gesture images if they don't exist
        self.ensure_gesture_images()
        
    def create_text_mappings(self):
        """Create mappings from text to gestures"""
        self.text_to_gesture = {}
        
        for class_id, gesture_info in self.labels.items():
            # Map English words
            english_words = gesture_info['english'].lower().split()
            for word in english_words:
                self.text_to_gesture[word] = gesture_info
            
            # Map gesture name
            self.text_to_gesture[gesture_info['name'].lower()] = gesture_info
            
            # Map Urdu and Pashto text
            self.text_to_gesture[gesture_info['urdu']] = gesture_info
            self.text_to_gesture[gesture_info['pashto']] = gesture_info
    
    def ensure_gesture_images(self):
        """Create sample gesture images if they don't exist"""
        from PIL import Image, ImageDraw, ImageFont
        
        for class_id, gesture_info in self.labels.items():
            image_path = self.images_path / f"{gesture_info['name']}.jpg"
            
            if not image_path.exists():
                self.create_sample_gesture_image(gesture_info, image_path)
    
    def create_sample_gesture_image(self, gesture_info, image_path):
        """Create a sample gesture demonstration image"""
        from PIL import Image, ImageDraw, ImageFont
        
        # Create a 400x300 image
        img = Image.new('RGB', (400, 300), color='white')
        draw = ImageDraw.Draw(img)
        
        # Try to load a font (fallback to default if not available)
        try:
            font_large = ImageFont.truetype("arial.ttf", 24)
            font_medium = ImageFont.truetype("arial.ttf", 18)
            font_small = ImageFont.truetype("arial.ttf", 14)
        except:
            font_large = ImageFont.load_default()
            font_medium = ImageFont.load_default()
            font_small = ImageFont.load_default()
        
        # Draw gesture information
        y_pos = 50
        
        # Gesture name
        draw.text((200, y_pos), gesture_info['name'].upper(), fill='black', 
                 font=font_large, anchor="mt")
        y_pos += 40
        
        # English meaning
        draw.text((200, y_pos), gesture_info['english'], fill='blue', 
                 font=font_medium, anchor="mt")
        y_pos += 30
        
        # Urdu text
        draw.text((200, y_pos), gesture_info['urdu'], fill='green', 
                 font=font_medium, anchor="mt")
        y_pos += 30
        
        # Pashto text  
        draw.text((200, y_pos), gesture_info['pashto'], fill='purple', 
                 font=font_medium, anchor="mt")
        y_pos += 50
        
        # Instructions
        draw.text((200, 250), "3D Character will demonstrate this gesture", fill='gray', 
                 font=font_small, anchor="mt")
        
        # Save image
        img.save(image_path)
        print(f"ğŸ“· Created sample image: {image_path}")
    
    def speech_to_sign(self):
        """Convert speech input to sign language gestures"""
        if not self.microphone:
            print("âŒ Microphone not available for speech recognition")
            return
            
        print("ğŸ¤ Speech to Sign Language Mode")
        print("ğŸ—£ï¸ Speak words in Urdu, Pashto, or English")
        print("ğŸ¤Ÿ The 3D character will demonstrate the gestures")
        print("âŒ Press Ctrl+C to return to main menu")
        
        try:
            while True:
                print("\n" + "="*60)
                print("ğŸ¤ Listening... (speak now)")
                
                recognized_text = self.listen_for_speech()
                
                if recognized_text:
                    print(f"ğŸ”¤ You said: '{recognized_text}'")
                    
                    # Find matching gesture
                    gesture_info = self.find_gesture_for_text(recognized_text)
                    
                    if gesture_info:
                        print(f"âœ… Found gesture: {gesture_info['name']}")
                        self.display_gesture_with_character(gesture_info)
                    else:
                        print("âŒ Sorry, no gesture found for that speech")
                        print("ğŸ’¡ Try saying: hello, thank you, water, food, help, one, two, three")
                        
                        if self.tts:
                            self.tts.say("Sorry, no matching gesture found. Try different words.")
                            self.tts.runAndWait()
                else:
                    print("ğŸ”„ No speech recognized. Please try again.")
                
                time.sleep(0.5)  # Brief pause before next iteration
                
        except KeyboardInterrupt:
            print("\nğŸ”™ Returning to main menu...")
    
    def text_to_sign(self):
        """Convert text input to sign language gestures"""
        print("âœï¸ Text to Sign Language Mode")
        print("ğŸ“ Type words in Urdu, Pashto, or English")
        print("ğŸ¤Ÿ The 3D character will demonstrate the gestures")
        print("âŒ Type 'quit' or 'exit' to return to main menu")
        
        while True:
            try:
                print("\n" + "="*60)
                text_input = input("ğŸ“ Enter text: ").strip()
                
                if text_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ”™ Returning to main menu...")
                    break
                    
                if not text_input:
                    continue
                
                print(f"ğŸ”¤ Processing: '{text_input}'")
                
                # Find matching gesture
                gesture_info = self.find_gesture_for_text(text_input)
                
                if gesture_info:
                    print(f"âœ… Found gesture: {gesture_info['name']}")
                    self.display_gesture_with_character(gesture_info)
                else:
                    print("âŒ Sorry, no gesture found for that text")
                    print("ğŸ’¡ Try typing: hello, thank you, water, food, help, one, two, three")
                    
                    if self.tts:
                        self.tts.say("Sorry, no matching gesture found. Try different words.")
                        self.tts.runAndWait()
                        
            except KeyboardInterrupt:
                print("\nğŸ”™ Returning to main menu...")
                break
    
    def listen_for_speech(self):
        """Listen for speech input using Google Speech API"""
        try:
            with self.microphone as source:
                # Listen for speech
                audio = self.recognizer.listen(source, timeout=8, phrase_time_limit=5)
                
            print("ğŸ”„ Processing speech...")
            
            # Get Google API key from environment
            google_api_key = os.getenv('GOOGLE_SPEECH_API_KEY')
            
            recognized_text = None
            
            # Try to recognize speech in multiple languages with API key
            try:
                # Try English first with API key
                text = self.recognizer.recognize_google(audio, key=google_api_key, language='en')
                print(f"ğŸ”¤ Recognized (English): {text}")
                recognized_text = text.lower()
            except:
                pass
            
            # If English failed, try Urdu
            if not recognized_text:
                try:
                    text = self.recognizer.recognize_google(audio, key=google_api_key, language='ur')
                    print(f"ğŸ”¤ Recognized (Urdu): {text}")
                    recognized_text = text
                except:
                    pass
            
            # If both failed, try Pashto (use Farsi as closest match)
            if not recognized_text:
                try:
                    text = self.recognizer.recognize_google(audio, key=google_api_key, language='fa')
                    print(f"ğŸ”¤ Recognized (Farsi/Pashto): {text}")
                    recognized_text = text
                except:
                    pass
                    
            # If all specific languages failed, try general recognition
            if not recognized_text:
                try:
                    text = self.recognizer.recognize_google(audio, key=google_api_key)
                    print(f"ğŸ”¤ Recognized (Auto): {text}")
                    recognized_text = text.lower()
                except:
                    pass
            
            return recognized_text
            
        except sr.WaitTimeoutError:
            print("â° No speech detected within timeout")
            return None
        except sr.UnknownValueError:
            print("â“ Could not understand speech")
            return None
        except sr.RequestError as e:
            print(f"âŒ Speech recognition error: {e}")
            # Fallback to free Google Speech Recognition
            try:
                with self.microphone as source:
                    audio = self.recognizer.listen(source, timeout=3, phrase_time_limit=3)
                text = self.recognizer.recognize_google(audio)
                print(f"ğŸ”¤ Recognized (Fallback): {text}")
                return text.lower()
            except:
                print("âŒ Fallback recognition also failed")
                return None
    
    def find_gesture_for_text(self, text):
        """Find matching gesture for recognized text"""
        if not text:
            return None
        
        text = text.lower().strip()
        print(f"ğŸ” Searching for gestures matching: '{text}'")
        
        # Direct match
        if text in self.text_to_gesture:
            return self.text_to_gesture[text]
        
        # Partial word matching
        for keyword, gesture_info in self.text_to_gesture.items():
            if isinstance(keyword, str):
                if keyword in text or text in keyword:
                    print(f"âœ… Found partial match: '{keyword}' in '{text}'")
                    return gesture_info
        
        # Check individual words
        words = text.split()
        for word in words:
            if word in self.text_to_gesture:
                return self.text_to_gesture[word]
        
        print("âŒ No matching gesture found")
        return None
    
    def display_gesture_with_character(self, gesture_info):
        """Display the gesture using 3D animated character"""
        print("=" * 50)
        print(f"ğŸ¤Ÿ GESTURE: {gesture_info['name'].upper()}")
        print(f"ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ English: {gesture_info['english']}")
        print(f"ğŸ‡µğŸ‡° Urdu: {gesture_info['urdu']}")
        print(f"ğŸ‡¦ğŸ‡« Pashto: {gesture_info['pashto']}")
        print("=" * 50)
        
        # Import and create 3D character
        try:
            from character_3d import SignLanguageCharacter
            
            print("ğŸ­ Starting 3D character animation...")
            print("ğŸ® The animated character will now demonstrate the gesture!")
            print("ğŸ® Press ESC or close the window when done watching")
            
            character = SignLanguageCharacter(width=900, height=700)
            
            # Animate the gesture
            success = character.run_animation_loop(gesture_info['name'], duration=5.0)
            character.cleanup()
            
            if success:
                print("âœ… 3D animation completed successfully!")
            else:
                print("âš ï¸ 3D animation was closed by user")
                
        except Exception as e:
            print(f"âš ï¸ Could not display 3D character: {e}")
            print("ğŸ“± The animated character feature requires a display")
            
        # Provide TTS feedback
        if self.tts:
            try:
                feedback = f"Gesture demonstrated: {gesture_info['english']}. In Urdu: {gesture_info['urdu']}. In Pashto: {gesture_info['pashto']}"
                print("ğŸ”Š Speaking gesture information...")
                self.tts.say(feedback)
                self.tts.runAndWait()
            except Exception as e:
                print(f"âš ï¸ TTS error: {e}")
    
    def show_available_gestures(self):
        """Show all available gestures"""
        print("\nğŸ¤Ÿ Available Pakistani Sign Language Gestures:")
        print("=" * 80)
        
        categories = {
            "Numbers": ["ek", "do", "teen", "chaar", "paanch", "che", "saat", "aath", "nau", "das"],
            "Greetings": ["salam", "shukriya", "khuda_hafiz"],
            "Family": ["ammi", "abbu", "bhai", "behn"],
            "Basic Needs": ["paani", "khana", "madad"],
            "Actions": ["reading", "writing", "listening", "speaking", "eating", "drinking"],
            "Objects": ["kitab", "qalam", "ghar", "school", "hospital"],
            "Emotions": ["khushi", "gham", "mohabbat"]
        }
        
        for category, gestures in categories.items():
            print(f"\nğŸ“‚ {category}:")
            for gesture in gestures:
                if gesture in [info['name'] for info in self.labels.values()]:
                    # Find the gesture info
                    for info in self.labels.values():
                        if info['name'] == gesture:
                            print(f"  ğŸ¤Ÿ {gesture:<12} | {info['english']:<15} | {info['urdu']:<10} | {info['pashto']}")
                            break
        
        print(f"\nğŸ“Š Total gestures available: {len(self.labels)}")
        print("ğŸ’¡ You can use any of these gestures in speech or text mode!")
    
    def run(self):
        """Run the main application"""
        print("\n" + "=" * 70)
        print("ğŸ‡µğŸ‡° PAKISTANI SIGN LANGUAGE TRANSLATION APP WITH 3D CHARACTER")
        print("=" * 70)
        print("ğŸ§  AI: YOLOv5 + Speech Recognition + 3D Animation")
        print("ğŸŒ Languages: Urdu, Pashto, English")
        print("ğŸ­ Features: 3D Animated Character Demonstrations")
        print("ğŸ¤Ÿ Gestures: 132 Pakistani Sign Language gestures")
        print("=" * 70)
        
        while True:
            try:
                print("\nğŸ¯ Choose an option:")
                print("1. ğŸ¤ Speech to Sign Language (with 3D character)")
                print("2. âœï¸  Text to Sign Language (with 3D character)")
                print("3. ğŸ“‹ Show Available Gestures")
                print("4. ğŸ­ Demo 3D Character")
                print("5. ğŸ“š Pakistani Story Mode (Ø§Ù†Ú¯ÙˆØ± ØªÙˆ Ú©Ú¾Ù¹Û’ ÛÛŒÚº)")
                print("6. âŒ Exit")
                
                choice = input("\nğŸ‘‰ Enter your choice (1-6): ").strip()
                
                if choice == '1':
                    self.speech_to_sign()
                elif choice == '2':
                    self.text_to_sign()
                elif choice == '3':
                    self.show_available_gestures()
                elif choice == '4':
                    self.demo_character()
                elif choice == '5':
                    self.run_story_mode()
                elif choice == '6':
                    print("ğŸ‘‹ Thank you for using Pakistani Sign Language App!")
                    print("ğŸ‡µğŸ‡° Goodbye! Ø®Ø¯Ø§ Ø­Ø§ÙØ¸! Ø®Ø¯Ø§ÛŒ Ù¾Ø§Ù…Ø§Ù†!")
                    break
                else:
                    print("âŒ Invalid choice. Please enter 1-6.")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ Application terminated by user")
                break
            except Exception as e:
                print(f"âŒ Unexpected error: {e}")
    
    def demo_character(self):
        """Demo the 3D character with sample gestures"""
        print("\nğŸ­ 3D Character Demo")
        print("ğŸ® The animated character will demonstrate various gestures")
        print("â° Each gesture will be shown for a few seconds")
        print("âŒ Press ESC or close window to stop demo")
        
        demo_gestures = [
            'salam', 'shukriya', 'khuda_hafiz',
            'ek', 'do', 'teen', 'chaar', 'paanch',
            'paani', 'khana', 'madad', 'ammi', 'abbu',
            'reading', 'writing', 'listening', 'speaking'
        ]
        
        try:
            from character_3d import SignLanguageCharacter
            character = SignLanguageCharacter(width=900, height=700)
            
            for gesture in demo_gestures:
                # Find gesture info
                gesture_info = None
                for info in self.labels.values():
                    if info['name'] == gesture:
                        gesture_info = info
                        break
                
                if gesture_info:
                    print(f"ğŸ­ Demonstrating: {gesture} ({gesture_info['english']})")
                    if not character.run_animation_loop(gesture, 3.0):
                        break
                    time.sleep(0.5)
                    
            character.cleanup()
            print("âœ… Demo completed!")
            
        except Exception as e:
            print(f"âŒ Could not run character demo: {e}")
    
    def pakistani_story_mode(self):
        """Interactive Pakistani story mode with sign language"""
        print("\nğŸ“š Pakistani Story Mode: Ø§Ù†Ú¯ÙˆØ± ØªÙˆ Ú©Ú¾Ù¹Û’ ÛÛŒÚº (The Grapes are Sour)")
        print("=" * 70)
        print("ğŸ¦Š A classic Aesop's fable in Pakistani context")
        print("ğŸ¤Ÿ Watch the story unfold with sign language gestures")
        print("ğŸ­ 3D character will demonstrate key words and phrases")
        print("âŒ Press ESC or close window to exit story mode")
        print("=" * 70)
        
        # Story segments with corresponding gestures
        story_segments = [
            {
                "text": "Ø§ÛŒÚ© Ø¯Ù†ØŒ Ø§ÛŒÚ© Ø¨Ú¾ÙˆÚ©Ø§ Ù„ÙˆÙ…Ú‘ÛŒ Ø¨Ø§Øº Ù…ÛŒÚº Ú¯Ú¾ÙˆÙ… Ø±ÛØ§ ØªÚ¾Ø§Û”",
                "english": "One day, a hungry fox was wandering in the garden.",
                "gestures": ["ek", "khana", "ghar"]
            },
            {
                "text": "Ø§Ø³ Ù†Û’ Ø§ÙˆÙ†Ú†ÛŒ Ø¨ÛŒÙ„ Ù¾Ø± Ù„Ù¹Ú©Û’ ÛÙˆØ¦Û’ Ø§Ù†Ú¯ÙˆØ± Ø¯ÛŒÚ©Ú¾Û’Û”",
                "english": "He saw grapes hanging on a high vine.",
                "gestures": ["paani", "khushi"]
            },
            {
                "text": "Ù„ÙˆÙ…Ú‘ÛŒ Ù†Û’ Ú©ÛØ§: 'ÛŒÛ Ø§Ù†Ú¯ÙˆØ± Ø¨ÛØª Ù…Ø²ÛŒØ¯Ø§Ø± Ù„Ú¯ Ø±ÛÛ’ ÛÛŒÚº!'",
                "english": "The fox said: 'These grapes look very delicious!'",
                "gestures": ["speaking", "khushi"]
            },
            {
                "text": "Ø§Ø³ Ù†Û’ Ø§Ú†Ú¾Ù„Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©ÛŒ Ù„ÛŒÚ©Ù† Ø§Ù†Ú¯ÙˆØ± ØªÚ© Ù†ÛÛŒÚº Ù¾ÛÙ†Ú† Ø³Ú©Ø§Û”",
                "english": "He tried to jump but couldn't reach the grapes.",
                "gestures": ["madad", "gham"]
            },
            {
                "text": "Ø¨Ø§Ø± Ø¨Ø§Ø± Ú©ÙˆØ´Ø´ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ù„ÙˆÙ…Ú‘ÛŒ ØªÚ¾Ú© Ú¯ÛŒØ§Û”",
                "english": "After trying many times, the fox got tired.",
                "gestures": ["gham", "madad"]
            },
            {
                "text": "Ø¢Ø®Ø± Ù…ÛŒÚº Ø§Ø³ Ù†Û’ Ú©ÛØ§: 'ÛŒÛ Ø§Ù†Ú¯ÙˆØ± ØªÙˆ Ú©Ú¾Ù¹Û’ ÛÛŒÚº!'",
                "english": "Finally he said: 'These grapes are sour!'",
                "gestures": ["speaking", "gham"]
            },
            {
                "text": "Ø§ÙˆØ± ÙˆÛ ÙˆØ§Ù¾Ø³ Ú†Ù„Ø§ Ú¯ÛŒØ§Û”",
                "english": "And he went back.",
                "gestures": ["khuda_hafiz"]
            }
        ]
        
        moral = {
            "urdu": "Ø³Ø¨Ù‚: Ø¬Ùˆ Ú†ÛŒØ² ÛÙ…ÛŒÚº Ù†ÛÛŒÚº Ù…Ù„ Ø³Ú©ØªÛŒØŒ ÛÙ… Ø§Ø³Û’ Ø¨Ø±Ø§ Ú©ÛÛ Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ”",
            "english": "Moral: We often despise what we cannot have.",
            "gestures": ["kitab", "mohabbat"]
        }
        
        try:
            from character_3d import SignLanguageCharacter
            character = SignLanguageCharacter(width=900, height=700)
            
            print("\nğŸ¬ Story begins...")
            time.sleep(2)
            
            for i, segment in enumerate(story_segments, 1):
                print(f"\nğŸ“– Part {i}:")
                print(f"ğŸ‡µğŸ‡° {segment['text']}")
                print(f"ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ {segment['english']}")
                
                # Demonstrate key gestures for this segment
                print("ğŸ¤Ÿ Key gestures for this part:")
                for gesture_name in segment['gestures']:
                    # Find gesture info
                    gesture_info = None
                    for info in self.labels.values():
                        if info['name'] == gesture_name:
                            gesture_info = info
                            break
                    
                    if gesture_info:
                        print(f"  ğŸ­ Demonstrating: {gesture_name} ({gesture_info['english']})")
                        if not character.run_animation_loop(gesture_name, 2.0):
                            character.cleanup()
                            return
                        time.sleep(0.5)
                
                # Pause between segments
                input("\nâ¸ï¸  Press Enter to continue to next part...")
            
            # Show moral of the story
            print("\n" + "=" * 50)
            print("ğŸ“š MORAL OF THE STORY:")
            print(f"ğŸ‡µğŸ‡° {moral['urdu']}")
            print(f"ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ {moral['english']}")
            print("=" * 50)
            
            # Demonstrate moral gestures
            print("ğŸ¤Ÿ Final gestures:")
            for gesture_name in moral['gestures']:
                gesture_info = None
                for info in self.labels.values():
                    if info['name'] == gesture_name:
                        gesture_info = info
                        break
                
                if gesture_info:
                    print(f"  ğŸ­ Demonstrating: {gesture_name} ({gesture_info['english']})")
                    if not character.run_animation_loop(gesture_name, 3.0):
                        break
                    time.sleep(0.5)
            
            character.cleanup()
            print("\nâœ… Story completed! Thank you for watching!")
            print("ğŸ“ You learned sign language through storytelling!")
            
            # TTS feedback
            if self.tts:
                self.tts.say("Story completed! You learned Pakistani sign language through the tale of the fox and grapes.")
                self.tts.runAndWait()
                
        except Exception as e:
            print(f"âŒ Could not run story mode: {e}")
            print("ğŸ“± Story mode requires a display for 3D character")

def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description='Pakistani Sign Language Translation with 3D Character')
    parser.add_argument('--labels', default='labels.json', help='Path to labels file')
    parser.add_argument('--images', default='gesture_images/', help='Path to gesture images directory')
    
    args = parser.parse_args()
    
    # Create and run the application
    app = PakistaniSignLanguageApp(labels_path=args.labels, images_path=args.images)
    app.run()

if __name__ == "__main__":
    main()